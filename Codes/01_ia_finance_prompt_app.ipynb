{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c351416",
   "metadata": {},
   "source": [
    "# IA financière + Prompt Engineering (sortie texte)\n",
    "\n",
    "Ce parcours couvre :\n",
    "1) Rédiger un prompt efficace pour l’analyse financière  \n",
    "2) Tester le prompt sur un **tableau** (KPIs calculés)  \n",
    "3) Créer un premier script Python avec l’API OpenAI (réponse texte)  \n",
    "4) Transformer un prompt en **outil réutilisable**  \n",
    "5) Créer une **interface Gradio** pour tester plusieurs prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f171a",
   "metadata": {},
   "source": [
    "## 1) Rédiger un prompt efficace pour l’analyse financière\n",
    "\n",
    "**Objectif** : construire des prompts **clairs** et **contextualisés** pour analyser des **données financières**.  \n",
    "**Idées clés** :\n",
    "- **Rôle & contexte** : précisez le rôle de l’IA (ex. *analyste financier senior*) et le contexte (secteur, période, type de données).  \n",
    "- **Tâche** : décrivez exactement ce que vous voulez (résumé, KPIs, risques, recommandations).  \n",
    "- **Contraintes** : ton professionnel, concision, citer les chiffres avec unité/devise, éviter le jargon inutile.  \n",
    "- **Format de sortie** : imposez **JSON** (clé/valeurs) pour exploiter facilement la réponse dans du code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae203566",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"Vous etes un(e) analyste financier(ere) senior.\n",
    "Contexte : {context}\n",
    "Donnees fournies : {data_desc}\n",
    "\n",
    "Taches (sortie texte) :\n",
    "1) Resume (5 lignes max) clair et actionnable.\n",
    "2) KPIs clefs (3 puces) au format : Nom - Valeur Unite/Devise (citer le chiffre exact).\n",
    "3) Risques (2 puces) avec justification d'une ligne.\n",
    "4) Actions proposees (3 puces) pour un decideur non specialiste.\n",
    "\n",
    "Contraintes :\n",
    "- Ton professionnel et concis ; eviter le jargon.\n",
    "- Toujours citer les chiffres avec unite/devise (ex. M USD, %, etc.).\n",
    "- Sortie en TEXTE : titres + listes a puces, pas de JSON.\n",
    "\"\"\"\n",
    "PROMPT_TEMPLATE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4e56c",
   "metadata": {},
   "source": [
    "# Préparation et importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49826c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance openai pandas numpy matplotlib gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ---------------------- Import Yahoo Finance (Adj Close) ----------------------\n",
    "UNIVERSE   = [\"AAPL\",\"MSFT\",\"JPM\",\"XOM\"]   # modifiez librement\n",
    "START_DATE = \"2020-01-01\"\n",
    "END_DATE   = None  # jusqu'a aujourd'hui\n",
    "\n",
    "# Telechargement des donnees (on suit exactement votre snippet)\n",
    "data = yf.download(UNIVERSE, start=START_DATE, end=END_DATE, progress=False, auto_adjust=False)\n",
    "\n",
    "# Si plusieurs tickers, on prend la colonne 'Adj Close'\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    prices = data[\"Adj Close\"].copy()           # colonnes = tickers\n",
    "else:\n",
    "    prices = data[[\"Adj Close\"]].copy()         # colonnes = [\"Adj Close\"]\n",
    "    if isinstance(UNIVERSE, list) and len(UNIVERSE) == 1:\n",
    "        prices.columns = [UNIVERSE[0]]          # renommer la colonne unique en nom du ticker\n",
    "\n",
    "# Apercu brut\n",
    "print(\"Apercu du tableau de prix (Adj Close) :\")\n",
    "print(prices.head())\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# KPIs sur la base des prix\n",
    "rets = np.log(prices).diff()\n",
    "win = 20  # fenetre pour volatilite realisee (approx. 1 mois de bourse)\n",
    "\n",
    "kpis = []\n",
    "for col in prices.columns:\n",
    "    s = prices[col].dropna()\n",
    "    r = rets[col].dropna()\n",
    "    last_price = float(s.iloc[-1]) if len(s) else np.nan\n",
    "    r_1m = float(np.exp(r.iloc[-21:].sum()) - 1) if len(r) >= 21 else np.nan\n",
    "    r_3m = float(np.exp(r.iloc[-63:].sum()) - 1) if len(r) >= 63 else np.nan\n",
    "    vol20 = float(r.iloc[-win:].std() * np.sqrt(252)) if len(r) >= win else np.nan\n",
    "    kpis.append({\n",
    "        \"ticker\": col,\n",
    "        \"last_price\": last_price,\n",
    "        \"return_1m\": r_1m,\n",
    "        \"return_3m\": r_3m,\n",
    "        \"vol20_annualized\": vol20\n",
    "    })\n",
    "\n",
    "df_kpis = pd.DataFrame(kpis)\n",
    "display(df_kpis)\n",
    "\n",
    "# Formatter propre pour injection dans le prompt\n",
    "k = df_kpis.copy()\n",
    "k[\"last_price\"]        = k[\"last_price\"].map(lambda x: f\"{x:,.2f} USD\" if pd.notnull(x) else \"NA\")\n",
    "k[\"return_1m\"]         = k[\"return_1m\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "k[\"return_3m\"]         = k[\"return_3m\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "k[\"vol20_annualized\"]  = k[\"vol20_annualized\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "\n",
    "DATA_DESC_YF = \"KPIs (Yahoo Finance):\\n\" + k.to_string(index=False)\n",
    "print(\"\\n=== Description pour le prompt ===\\n\", DATA_DESC_YF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeab434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports communs\n",
    "import os, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# Détection  de la clé API\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "print(\"OPENAI_API_KEY défini :\", api_key[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd401a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"Portefeuille multi-secteurs, horizon court terme.\"\n",
    "prompt_yf = PROMPT_TEMPLATE.format(context=CONTEXT, data_desc=DATA_DESC_YF)\n",
    "\n",
    "resp_yf = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\":\"user\",\"content\": prompt_yf}],\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(resp_yf.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(context: str, data_desc: str, extra: str = \"\", model: str = \"gpt-4o-mini\", temperature: float = 0.2) -> str:\n",
    "    \"\"\"Construit le prompt et renvoie la reponse TEXTE (pas de JSON).\"\"\"\n",
    "    prompt_here = PROMPT_TEMPLATE.format(context=context, data_desc=data_desc)\n",
    "    if extra:\n",
    "        prompt_here += \"\\n\\nConsignes additionnelles :\\n\" + extra\n",
    "    r = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\": prompt_here}],\n",
    "        temperature=float(temperature),\n",
    "    )\n",
    "    return r.choices[0].message.content\n",
    "\n",
    "# Exemple rapide : rejouer sur les KPIs Yahoo\n",
    "print(run_prompt(CONTEXT, DATA_DESC_YF, extra=\"Souligne les divergences sectorielles et propose 3 actions.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcea7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def ui_from_yahoo(tickers_csv, start, end, context, extra, model, temperature):\n",
    "    # Parse tickers\n",
    "    UNIVERSE = [t.strip().upper() for t in tickers_csv.split(\",\") if t.strip()]\n",
    "    START_DATE = start or \"2020-01-01\"\n",
    "    END_DATE   = end if end not in (\"\", None) else None\n",
    "\n",
    "    # Import EXACTEMENT comme votre snippet (Adj Close)\n",
    "    data = yf.download(UNIVERSE, start=START_DATE, end=END_DATE, progress=False, auto_adjust=False)\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        prices = data[\"Adj Close\"].copy()\n",
    "    else:\n",
    "        prices = data[[\"Adj Close\"]].copy()\n",
    "        if len(UNIVERSE) == 1:\n",
    "            prices.columns = [UNIVERSE[0]]\n",
    "\n",
    "    prices = prices.dropna(how=\"all\")\n",
    "    rets = np.log(prices).diff()\n",
    "\n",
    "    # KPIs\n",
    "    win = 20\n",
    "    kpis = []\n",
    "    for col in prices.columns:\n",
    "        s = prices[col].dropna()\n",
    "        r = rets[col].dropna()\n",
    "        last_price = float(s.iloc[-1]) if len(s) else np.nan\n",
    "        r_1m = float(np.exp(r.iloc[-21:].sum()) - 1) if len(r) >= 21 else np.nan\n",
    "        r_3m = float(np.exp(r.iloc[-63:].sum()) - 1) if len(r) >= 63 else np.nan\n",
    "        vol20 = float(r.iloc[-win:].std() * np.sqrt(252)) if len(r) >= win else np.nan\n",
    "        kpis.append({\"ticker\": col, \"last_price\": last_price, \"return_1m\": r_1m, \"return_3m\": r_3m, \"vol20_annualized\": vol20})\n",
    "\n",
    "    df_k = pd.DataFrame(kpis).copy()\n",
    "    df_k[\"last_price\"]       = df_k[\"last_price\"].map(lambda x: f\"{x:,.2f} USD\" if pd.notnull(x) else \"NA\")\n",
    "    df_k[\"return_1m\"]        = df_k[\"return_1m\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "    df_k[\"return_3m\"]        = df_k[\"return_3m\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "    df_k[\"vol20_annualized\"] = df_k[\"vol20_annualized\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "\n",
    "    data_desc = \"KPIs (Yahoo Finance):\\n\" + df_k.to_string(index=False)\n",
    "    txt = run_prompt(context, data_desc, extra=extra, model=model, temperature=temperature)\n",
    "    return txt, data_desc\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Yahoo Finance -> KPIs -> Prompt (sortie texte)\")\n",
    "    with gr.Row():\n",
    "        tickers_in = gr.Textbox(label=\"Tickers (CSV)\", value=\"AAPL,MSFT,JPM,XOM\")\n",
    "        start_in   = gr.Textbox(label=\"Start (YYYY-MM-DD)\", value=\"2020-01-01\")\n",
    "        end_in     = gr.Textbox(label=\"End (YYYY-MM-DD ou vide)\", value=\"\")\n",
    "    context_in = gr.Textbox(label=\"Contexte\", value=\"Portefeuille multi-secteurs, horizon court terme.\", lines=2)\n",
    "    extra_in   = gr.Textbox(label=\"Consignes additionnelles\", value=\"Souligne les divergences sectorielles et propose 3 actions.\", lines=2)\n",
    "    with gr.Row():\n",
    "        model_in = gr.Dropdown(label=\"Modele\", choices=[\"gpt-4o-mini\",\"gpt-4o\"], value=\"gpt-4o-mini\")\n",
    "        temp_in  = gr.Slider(label=\"Temperature\", minimum=0.0, maximum=1.0, step=0.1, value=0.2)\n",
    "\n",
    "    run_btn = gr.Button(\"Analyser\")\n",
    "    out_text = gr.Textbox(label=\"Reponse (texte)\", lines=14)\n",
    "    out_prompt = gr.Code(label=\"Tableau KPIs injecte\", language=\"markdown\")\n",
    "\n",
    "    run_btn.click(ui_from_yahoo,\n",
    "                  inputs=[tickers_in, start_in, end_in, context_in, extra_in, model_in, temp_in],\n",
    "                  outputs=[out_text, out_prompt])\n",
    "\n",
    "# Pour lancer l'interface :\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf760d67",
   "metadata": {},
   "source": [
    "## Défi — Refaire l’application **100% local** avec Ollama\n",
    "\n",
    "**Objectif.** Reprendre votre mini-application (KPIs Yahoo Finance → prompt engineering → réponse texte) et la refaire **sans aucun appel cloud**, en utilisant **uniquement Ollama** en local.\n",
    "\n",
    "### Contraintes\n",
    "- **Modèle** : un LLM open-source lancé via Ollama (ex. `llama3:8b`, `mistral:7b-instruct`, `qwen2.5:7b-instruct`).\n",
    "- **Package** : utiliser le package Python `ollama` (`pip install ollama`), pas l’API OpenAI.\n",
    "- **Données** : récupérer les prix avec **Yahoo Finance** (`yfinance`), calculer au minimum : **dernier cours**, **rendement 1 mois**, **rendement 3 mois**, **volatilité 20j annualisée**.\n",
    "- **Prompt** : réutiliser le **template en sortie texte** (titres + puces, **pas de JSON**), en injectant votre tableau de KPIs formaté.\n",
    "- **Sortie** : texte clair en français (résumé ≤ 5 lignes, 3 KPIs en puces, 2 risques en puces, 3 actions en puces).\n",
    "\n",
    "### À faire (checklist)\n",
    "1. **Installer** et démarrer Ollama, puis tirer un modèle :  \n",
    "   `ollama pull llama3:8b`\n",
    "2. **Calculer les KPIs** (Yahoo Finance) et construire un texte `data_desc` lisible (tableau formaté).\n",
    "3. **Construire le prompt** (même structure que précédemment : contexte + `data_desc` + consignes).\n",
    "4. **Générer localement** avec `ollama.chat` (sortie **texte** uniquement, pas de JSON).\n",
    "5. **Comparer** rapidement la réponse locale vs la version cloud : clarté, précision chiffrée, ton.\n",
    "\n",
    "### Livrables attendus\n",
    "- Le **script/notebook** complet (import YF, KPIs, prompt, appel `ollama.chat`).\n",
    "- Le **prompt final** injecté (copié en clair).\n",
    "- La **réponse texte** du modèle (résumé, 3 KPIs, 2 risques, 3 actions).\n",
    "- 3–5 lignes de **retour d’expérience** (vitesse, qualité, limites, pistes d’amélioration : quantisation, autre modèle, séparation par secteurs…).\n",
    "\n",
    "> Astuce : si le modèle « oublie » les chiffres, **raccourcissez** le tableau (top 4–6 tickers), **réitérez** la consigne « citer les chiffres avec unité/devise » et baissez la **température** (≈ 0.2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7ba88",
   "metadata": {},
   "source": [
    "# LLM local\n",
    "ollama pull llama3:8b\n",
    "# Librairies Python\n",
    "pip install ollama yfinance pandas numpy matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30460a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama yfinance pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1704af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Mini-application IA financière — Solution 100% locale (Ollama)\n",
    "# KPIs Yahoo Finance -> Prompt engineering (texte) -> Réponse locale\n",
    "# AUCUN appel cloud (OpenAI non utilisé)\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import ollama\n",
    "\n",
    "# ------------------ Paramètres ------------------\n",
    "TICKERS     = [\"AAPL\", \"MSFT\", \"JPM\", \"XOM\"]   # modifiez votre univers\n",
    "START_DATE  = \"2020-01-01\"\n",
    "END_DATE    = None\n",
    "INTERVAL    = \"1d\"                             # \"1d\",\"1wk\",\"1mo\"\n",
    "LLM_MODEL   = \"llama3.1:8b\"                      # ex. \"llama3:8b\", \"mistral:7b-instruct\", \"qwen2.5:7b-instruct\"\n",
    "TEMP        = 0.2\n",
    "\n",
    "# ------------------ 1) Import YF (Adj Close) ------------------\n",
    "raw = yf.download(\n",
    "    TICKERS,\n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    interval=INTERVAL,\n",
    "    auto_adjust=False,     # on lit bien 'Adj Close'\n",
    "    progress=False,\n",
    "    group_by=\"column\"\n",
    ")\n",
    "\n",
    "if isinstance(raw.columns, pd.MultiIndex):\n",
    "    prices = raw[\"Adj Close\"].copy()           # colonnes = tickers\n",
    "else:\n",
    "    prices = raw[[\"Adj Close\"]].copy()         # colonnes = [\"Adj Close\"]\n",
    "    if isinstance(TICKERS, list) and len(TICKERS) == 1:\n",
    "        prices.columns = [TICKERS[0]]\n",
    "\n",
    "prices = prices.dropna(how=\"all\")\n",
    "print(\"Aperçu des prix (Adj Close) :\")\n",
    "print(prices.head())\n",
    "\n",
    "# ------------------ 2) KPIs sur les prix ------------------\n",
    "# Rendements log\n",
    "rets = np.log(prices).diff()\n",
    "\n",
    "# KPIs : dernier cours, performance 1m (~21 j) / 3m (~63 j), vol 20j annualisée\n",
    "win = 20\n",
    "rows = []\n",
    "for col in prices.columns:\n",
    "    s = prices[col].dropna()\n",
    "    r = rets[col].dropna()\n",
    "    last_price = float(s.iloc[-1]) if len(s) else np.nan\n",
    "    r_1m = float(np.exp(r.iloc[-21:].sum()) - 1) if len(r) >= 21 else np.nan\n",
    "    r_3m = float(np.exp(r.iloc[-63:].sum()) - 1) if len(r) >= 63 else np.nan\n",
    "    vol20 = float(r.iloc[-win:].std() * np.sqrt(252)) if len(r) >= win else np.nan\n",
    "    rows.append({\n",
    "        \"ticker\": col,\n",
    "        \"last_price\": last_price,\n",
    "        \"return_1m\": r_1m,\n",
    "        \"return_3m\": r_3m,\n",
    "        \"vol20_annualized\": vol20\n",
    "    })\n",
    "\n",
    "df_kpis = pd.DataFrame(rows)\n",
    "print(\"\\nKPIs bruts :\")\n",
    "print(df_kpis)\n",
    "\n",
    "# Mise en forme pour un tableau lisible à injecter dans le prompt\n",
    "k = df_kpis.copy()\n",
    "k[\"last_price\"]        = k[\"last_price\"].map(lambda x: f\"{x:,.2f} USD\" if pd.notnull(x) else \"NA\")\n",
    "k[\"return_1m\"]         = k[\"return_1m\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "k[\"return_3m\"]         = k[\"return_3m\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "k[\"vol20_annualized\"]  = k[\"vol20_annualized\"].map(lambda x: f\"{x*100:.2f} %\" if pd.notnull(x) else \"NA\")\n",
    "\n",
    "DATA_DESC = \"KPIs (Yahoo Finance):\\n\" + k.to_string(index=False)\n",
    "print(\"\\n=== Données injectées dans le prompt ===\\n\", DATA_DESC)\n",
    "\n",
    "# ------------------ 3) Prompt template (sortie TEXTE) ------------------\n",
    "PROMPT_TEMPLATE = \"\"\"Vous etes un(e) analyste financier(ere) senior.\n",
    "Contexte : {context}\n",
    "Donnees fournies : {data_desc}\n",
    "\n",
    "Taches (sortie texte) :\n",
    "1) Resume (5 lignes max) clair et actionnable.\n",
    "2) KPIs clefs (3 puces) au format : Nom - Valeur Unite/Devise (citer le chiffre exact).\n",
    "3) Risques (2 puces) avec justification d'une ligne.\n",
    "4) Actions proposees (3 puces) pour un decideur non specialiste.\n",
    "\n",
    "Contraintes :\n",
    "- Ton professionnel et concis ; eviter le jargon.\n",
    "- Toujours citer les chiffres avec unite/devise (ex. M USD, %, etc.).\n",
    "- Sortie en TEXTE : titres + listes a puces + commentaires et interprétations\n",
    "\"\"\"\n",
    "\n",
    "CONTEXT = \"Portefeuille multi-secteurs, horizon court terme.\"\n",
    "prompt = PROMPT_TEMPLATE.format(context=CONTEXT, data_desc=DATA_DESC)\n",
    "\n",
    "# ------------------ 4) Génération locale avec Ollama ------------------\n",
    "system_msg = (\n",
    "    \"Tu es un analyste financier. Reponds uniquement a partir des donnees fournies. \"\n",
    "    \"Sortie en TEXTE (titres + puces + commentaires et interprétations) \"\n",
    "    \"Cite clairement les chiffres avec leur unite/devise.\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_msg},\n",
    "    {\"role\": \"user\",   \"content\": prompt}\n",
    "]\n",
    "\n",
    "print(\"\\n=== Prompt (récapitulatif) ===\\n\")\n",
    "print(prompt[:1000] + (\"\\n... (tronqué)\" if len(prompt) > 1000 else \"\"))\n",
    "\n",
    "resp = ollama.chat(\n",
    "    model=LLM_MODEL,\n",
    "    messages=messages,\n",
    "    options={\"temperature\": TEMP}\n",
    ")\n",
    "\n",
    "print(\"\\n=== Réponse du modèle (Ollama local) ===\\n\")\n",
    "print(resp[\"message\"][\"content\"])\n",
    "\n",
    "# ============================================================\n",
    "# Fin — Solution locale : aucun appel cloud, tout en local.\n",
    "# ============================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
